{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-l6jQIlto9P",
    "outputId": "a02d7f85-26af-4043-adae-b70028ea8ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Columns: 105 entries, uniq_id to Unnamed: 104\n",
      "dtypes: float64(3), object(102)\n",
      "memory usage: 16.0+ MB\n",
      "uniq_id                      0\n",
      "crawl_timestamp              0\n",
      "product_url                  0\n",
      "product_name                 0\n",
      "product_category_tree        0\n",
      "                         ...  \n",
      "Unnamed: 100             19994\n",
      "Unnamed: 101             19994\n",
      "Unnamed: 102             19994\n",
      "Unnamed: 103             19994\n",
      "Unnamed: 104             19994\n",
      "Length: 103, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(\"flipdata.xlsx\")\n",
    "\n",
    "# convert the 'discounted_price' and 'retail_price' columns to numeric\n",
    "df['discounted_price'] = pd.to_numeric(df['discounted_price'], errors='coerce')\n",
    "df['retail_price'] = pd.to_numeric(df['retail_price'], errors='coerce')\n",
    "\n",
    "#product ratings(replace all values which have a string with 0)\n",
    "df['product_rating'] = pd.to_numeric(df['product_rating'], errors='coerce')\n",
    "df['product_rating'] = df['product_rating'].astype('float64')\n",
    "df.info()\n",
    "\n",
    "\n",
    "#dropping columns\n",
    "df.drop(columns=['pid','overall_rating'], inplace=True)\n",
    "\n",
    "#HANDLING MISSING VALUES\n",
    "\n",
    "#2. brand (filling missing values with a placeholder)\n",
    "\n",
    "df['brand'] = df['brand'].fillna('Unknown')\n",
    "# Convert 'brand' column to string type before creating the treemap\n",
    "df['brand'] = df['brand'].astype(str)\n",
    "\n",
    "\n",
    "#3. images (dropping the rows may have a minimal impact on analysis since only 78 are affected.)\n",
    "\n",
    "df = df.dropna(subset=['image'])\n",
    "\n",
    "#4. description (dropping the rows may have a minimal impact on analysis since only 2 are affected.)\n",
    "\n",
    "df = df.dropna(subset=['description'])\n",
    "\n",
    "#5. product specifications(filling missing values with a placeholder)\n",
    "\n",
    "df['product_specifications'] = df['product_specifications'].fillna('Not Available')\n",
    "\n",
    "\n",
    "#1. retail price and discounted price\n",
    "\n",
    "# Columns with missing values to impute\n",
    "columns_to_impute = ['retail_price', 'discounted_price']\n",
    "\n",
    "# Create imputed DataFrames for mean, median, and mode imputation\n",
    "df_mean_imputed = df.copy()\n",
    "df_mean_imputed[columns_to_impute] = df[columns_to_impute].fillna(df[columns_to_impute].mean())\n",
    "\n",
    "df_median_imputed = df.copy()\n",
    "df_median_imputed[columns_to_impute] = df[columns_to_impute].fillna(df[columns_to_impute].median())\n",
    "\n",
    "df_mode_imputed = df.copy()\n",
    "for col in columns_to_impute:\n",
    "    df_mode_imputed[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Initialize a final DataFrame to store the best imputation for each column\n",
    "df_final = df.copy()\n",
    "\n",
    "# Function to calculate the best imputation based on minimum differences\n",
    "for column in columns_to_impute:\n",
    "    # Calculate absolute differences in mean, median, and standard deviation\n",
    "    a1 = abs(df[column].mean() - df_mean_imputed[column].mean())\n",
    "    b1 = abs(df[column].mean() - df_median_imputed[column].mean())\n",
    "    c1 = abs(df[column].mean() - df_mode_imputed[column].mean())\n",
    "\n",
    "    a2 = abs(df[column].median() - df_mean_imputed[column].median())\n",
    "    b2 = abs(df[column].median() - df_median_imputed[column].median())\n",
    "    c2 = abs(df[column].median() - df_mode_imputed[column].median())\n",
    "\n",
    "    a3 = abs(df[column].std() - df_mean_imputed[column].std())\n",
    "    b3 = abs(df[column].std() - df_median_imputed[column].std())\n",
    "    c3 = abs(df[column].std() - df_mode_imputed[column].std())\n",
    "\n",
    "    # Sum of differences for mean, median, and std\n",
    "    a = a1 + a2 + a3\n",
    "    b = b1 + b2 + b3\n",
    "    c = c1 + c2 + c3\n",
    "\n",
    "    # Choose the imputation method with the smallest difference\n",
    "    min_value = min(a, b, c)\n",
    "    if min_value == a:\n",
    "        df_final[column] = df_mean_imputed[column]\n",
    "    elif min_value == b:\n",
    "        df_final[column] = df_median_imputed[column]\n",
    "    else:\n",
    "        df_final[column] = df_mode_imputed[column]\n",
    "\n",
    "# Save and display the cleaned dataset\n",
    "print(df_final.isnull().sum())\n",
    "df_final.to_excel(\"flipdata_11.xlsx\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jLHh1qR--bMJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(\"flipdata_11.xlsx\")\n",
    "\n",
    "#removing duplicates\n",
    "duplicates = df.duplicated()\n",
    "df_unique = df.drop_duplicates()\n",
    "\n",
    "# drop all the rows where value in column 'discounted_price' is greater tha value in column 'retail_price'\n",
    "x=df[df['discounted_price'] > df['retail_price']]\n",
    "df.drop(x.index, inplace=True)\n",
    "\n",
    "df.to_excel(\"flipdata_22.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "a0m_Ui825gSS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(\"flipdata_22.xlsx\")\n",
    "\n",
    "#HANDLING OUTLIERS\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = df['retail_price'].quantile(0.25)\n",
    "Q3 = df['retail_price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier boundaries\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out outliers\n",
    "df_filtered = df[(df['retail_price'] >= lower_bound) & (df['retail_price'] <= upper_bound)]\n",
    "\n",
    "df.to_excel(\"flipdata_33.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clRWkwHE5yHG",
    "outputId": "dcd1f3f0-c264-496a-dfd2-dbf96ce7882a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AtharvaShah\\AppData\\Local\\Temp\\ipykernel_7344\\3044141061.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['time'] = pd.to_datetime(df['time'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(\"flipdata_33.xlsx\")\n",
    "#making new column for discount percentage\n",
    "\n",
    "df = df.assign(discount_percentage=((df['retail_price'] - df['discounted_price']) / df['retail_price']) * 100)\n",
    "\n",
    "df[['discount_percentage','retail_price','discounted_price']].head()\n",
    "\n",
    "#splitting timestamp column\n",
    "\n",
    "df[['date', 'time', 'stamp']] = df['crawl_timestamp'].str.split(' ', expand=True, n=3)\n",
    "df.drop(columns=['stamp', 'crawl_timestamp'], inplace=True)\n",
    "\n",
    "#converting timestamp into proper format\n",
    "\n",
    "if not pd.api.types.is_datetime64_any_dtype(df['time']):\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "if not pd.api.types.is_datetime64_any_dtype(df['date']):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "#splitting category column\n",
    "\n",
    "# Split the 'product_category_tree' column into three parts and ignore any additional segments\n",
    "df[['category', 'type', 'style', 'sub_category']] = df['product_category_tree'].str.split('>>', n=3, expand=True)\n",
    "\n",
    "# Delete the original 'product_category_tree' column and the 'sub_category'\n",
    "df.drop(columns=['product_category_tree'], inplace=True)\n",
    "df.drop(columns=['sub_category'], inplace=True)\n",
    "\n",
    "# Save the updated DataFrame back to Excel if needed\n",
    "#df.to_excel(\"flipdata.xlsx\", index=False)\n",
    "\n",
    "\n",
    "# Get the unique values from the 'category' column\n",
    "category_values = df['category'].unique()\n",
    "\n",
    "# Iterate through the unique category values\n",
    "for col in category_values:\n",
    "    # Replace '[' in the 'category' column for each category value\n",
    "    df['category'] = df['category'].str.replace('[', '', regex=False)\n",
    "\n",
    "# Get the unique values from the 'category' column\n",
    "category_values = df['category'].unique()\n",
    "\n",
    "# Iterate through the unique category values\n",
    "for col in category_values:\n",
    "    # Replace '[' in the 'category' column for each category value\n",
    "    df['category'] = df['category'].str.replace('\"', '', regex=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.to_excel(\"flipdata_44.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

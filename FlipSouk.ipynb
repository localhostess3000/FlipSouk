{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-l6jQIlto9P",
        "outputId": "a02d7f85-26af-4043-adae-b70028ea8ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-3d3b995c7391>:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['product_rating'] = df['product_rating'].replace('No rating available',0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 15 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   uniq_id                  20000 non-null  object \n",
            " 1   crawl_timestamp          20000 non-null  object \n",
            " 2   product_url              20000 non-null  object \n",
            " 3   product_name             20000 non-null  object \n",
            " 4   product_category_tree    20000 non-null  object \n",
            " 5   pid                      20000 non-null  object \n",
            " 6   retail_price             19922 non-null  float64\n",
            " 7   discounted_price         19922 non-null  float64\n",
            " 8   image                    19997 non-null  object \n",
            " 9   is_FK_Advantage_product  20000 non-null  bool   \n",
            " 10  description              19998 non-null  object \n",
            " 11  product_rating           20000 non-null  float64\n",
            " 12  overall_rating           20000 non-null  object \n",
            " 13  brand                    14136 non-null  object \n",
            " 14  product_specifications   19986 non-null  object \n",
            "dtypes: bool(1), float64(3), object(11)\n",
            "memory usage: 2.2+ MB\n",
            "uniq_id                    0\n",
            "crawl_timestamp            0\n",
            "product_url                0\n",
            "product_name               0\n",
            "product_category_tree      0\n",
            "retail_price               0\n",
            "discounted_price           0\n",
            "image                      0\n",
            "is_FK_Advantage_product    0\n",
            "description                0\n",
            "product_rating             0\n",
            "brand                      0\n",
            "product_specifications     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_excel(\"flipdata.xlsx\")\n",
        "\n",
        "# convert the 'discounted_price' and 'retail_price' columns to numeric\n",
        "df['discounted_price'] = pd.to_numeric(df['discounted_price'], errors='coerce')\n",
        "df['retail_price'] = pd.to_numeric(df['retail_price'], errors='coerce')\n",
        "\n",
        "#product ratings(change the type into float and remove 'no available rating string' and convert it into 0)\n",
        "\n",
        "df['product_rating'] = df['product_rating'].replace('No rating available',0)\n",
        "df['product_rating'] = df['product_rating'].astype('float64')\n",
        "df.info()\n",
        "\n",
        "\n",
        "#dropping columns\n",
        "df.drop(columns=['pid','overall_rating'], inplace=True)\n",
        "\n",
        "#HANDLING MISSING VALUES\n",
        "\n",
        "#2. brand (filling missing values with a placeholder)\n",
        "\n",
        "df['brand'] = df['brand'].fillna('Unknown')\n",
        "# Convert 'brand' column to string type before creating the treemap\n",
        "df['brand'] = df['brand'].astype(str)\n",
        "\n",
        "\n",
        "#3. images (dropping the rows may have a minimal impact on analysis since only 78 are affected.)\n",
        "\n",
        "df = df.dropna(subset=['image'])\n",
        "\n",
        "#4. description (dropping the rows may have a minimal impact on analysis since only 2 are affected.)\n",
        "\n",
        "df = df.dropna(subset=['description'])\n",
        "\n",
        "#5. product specifications(filling missing values with a placeholder)\n",
        "\n",
        "df['product_specifications'] = df['product_specifications'].fillna('Not Available')\n",
        "\n",
        "\n",
        "#1. retail price and discounted price\n",
        "\n",
        "# Columns with missing values to impute\n",
        "columns_to_impute = ['retail_price', 'discounted_price']\n",
        "\n",
        "# Create imputed DataFrames for mean, median, and mode imputation\n",
        "df_mean_imputed = df.copy()\n",
        "df_mean_imputed[columns_to_impute] = df[columns_to_impute].fillna(df[columns_to_impute].mean())\n",
        "\n",
        "df_median_imputed = df.copy()\n",
        "df_median_imputed[columns_to_impute] = df[columns_to_impute].fillna(df[columns_to_impute].median())\n",
        "\n",
        "df_mode_imputed = df.copy()\n",
        "for col in columns_to_impute:\n",
        "    df_mode_imputed[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "# Initialize a final DataFrame to store the best imputation for each column\n",
        "df_final = df.copy()\n",
        "\n",
        "# Function to calculate the best imputation based on minimum differences\n",
        "for column in columns_to_impute:\n",
        "    # Calculate absolute differences in mean, median, and standard deviation\n",
        "    a1 = abs(df[column].mean() - df_mean_imputed[column].mean())\n",
        "    b1 = abs(df[column].mean() - df_median_imputed[column].mean())\n",
        "    c1 = abs(df[column].mean() - df_mode_imputed[column].mean())\n",
        "\n",
        "    a2 = abs(df[column].median() - df_mean_imputed[column].median())\n",
        "    b2 = abs(df[column].median() - df_median_imputed[column].median())\n",
        "    c2 = abs(df[column].median() - df_mode_imputed[column].median())\n",
        "\n",
        "    a3 = abs(df[column].std() - df_mean_imputed[column].std())\n",
        "    b3 = abs(df[column].std() - df_median_imputed[column].std())\n",
        "    c3 = abs(df[column].std() - df_mode_imputed[column].std())\n",
        "\n",
        "    # Sum of differences for mean, median, and std\n",
        "    a = a1 + a2 + a3\n",
        "    b = b1 + b2 + b3\n",
        "    c = c1 + c2 + c3\n",
        "\n",
        "    # Choose the imputation method with the smallest difference\n",
        "    min_value = min(a, b, c)\n",
        "    if min_value == a:\n",
        "        df_final[column] = df_mean_imputed[column]\n",
        "    elif min_value == b:\n",
        "        df_final[column] = df_median_imputed[column]\n",
        "    else:\n",
        "        df_final[column] = df_mode_imputed[column]\n",
        "\n",
        "# Save and display the cleaned dataset\n",
        "print(df_final.isnull().sum())\n",
        "df_final.to_excel(\"flipdata_11.xlsx\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_excel(\"flipdata_44.xlsx\")\n",
        "\n",
        "missing_values = df.isna().sum()\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJez5Q6rD5n0",
        "outputId": "c92e3d9f-f9ba-4484-ea33-13fea4f8294a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uniq_id                       0\n",
            "product_url                   0\n",
            "product_name                  0\n",
            "retail_price                  0\n",
            "discounted_price              0\n",
            "image                         0\n",
            "is_FK_Advantage_product       0\n",
            "description                   0\n",
            "product_rating                0\n",
            "brand                         0\n",
            "product_specifications        0\n",
            "discount_percentage           0\n",
            "date                          0\n",
            "time                          0\n",
            "category                      0\n",
            "type                        325\n",
            "style                      1453\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_excel(\"flipdata_11.xlsx\")\n",
        "\n",
        "#removing duplicates\n",
        "duplicates = df.duplicated()\n",
        "df_unique = df.drop_duplicates()\n",
        "\n",
        "# drop all the rows where value in column 'discounted_price' is greater tha value in column 'retail_price'\n",
        "x=df[df['discounted_price'] > df['retail_price']]\n",
        "df.drop(x.index, inplace=True)\n",
        "\n",
        "df.to_excel(\"flipdata_22.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "jLHh1qR--bMJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_excel(\"flipdata_33.xlsx\")\n",
        "#making new column for discount percentage\n",
        "\n",
        "df = df.assign(discount_percentage=((df['retail_price'] - df['discounted_price']) / df['retail_price']) * 100)\n",
        "\n",
        "df[['discount_percentage','retail_price','discounted_price']].head()\n",
        "\n",
        "#splitting timestamp column\n",
        "\n",
        "df[['date', 'time', 'stamp']] = df['crawl_timestamp'].str.split(' ', expand=True, n=3)\n",
        "df.drop(columns=['stamp', 'crawl_timestamp'], inplace=True)\n",
        "\n",
        "#converting timestamp into proper format\n",
        "\n",
        "if not pd.api.types.is_datetime64_any_dtype(df['time']):\n",
        "    df['time'] = pd.to_datetime(df['time'])\n",
        "\n",
        "if not pd.api.types.is_datetime64_any_dtype(df['date']):\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "#splitting category column\n",
        "\n",
        "# Split the 'product_category_tree' column into three parts and ignore any additional segments\n",
        "df[['category', 'type', 'style', 'sub_category']] = df['product_category_tree'].str.split('>>', n=3, expand=True)\n",
        "\n",
        "# Delete the original 'product_category_tree' column and the 'sub_category'\n",
        "df.drop(columns=['product_category_tree'], inplace=True)\n",
        "df.drop(columns=['sub_category'], inplace=True)\n",
        "\n",
        "# Save the updated DataFrame back to Excel if needed\n",
        "#df.to_excel(\"flipdata.xlsx\", index=False)\n",
        "\n",
        "\n",
        "# Get the unique values from the 'category' column\n",
        "category_values = df['category'].unique()\n",
        "\n",
        "# Iterate through the unique category values\n",
        "for col in category_values:\n",
        "    # Replace '[' in the 'category' column for each category value\n",
        "    df['category'] = df['category'].str.replace('[', '', regex=False)\n",
        "\n",
        "# Get the unique values from the 'category' column\n",
        "category_values = df['category'].unique()\n",
        "\n",
        "# Iterate through the unique category values\n",
        "for col in category_values:\n",
        "    # Replace '[' in the 'category' column for each category value\n",
        "    df['category'] = df['category'].str.replace('\"', '', regex=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df.to_excel(\"flipdata_44.xlsx\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clRWkwHE5yHG",
        "outputId": "dcd1f3f0-c264-496a-dfd2-dbf96ce7882a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-61778de8f550>:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['time'] = pd.to_datetime(df['time'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_excel(\"flipdata_22.xlsx\")\n",
        "\n",
        "#HANDLING OUTLIERS\n",
        "\n",
        "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
        "Q1 = df['retail_price'].quantile(0.25)\n",
        "Q3 = df['retail_price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define outlier boundaries\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filter out outliers\n",
        "df_filtered = df[(df['retail_price'] >= lower_bound) & (df['retail_price'] <= upper_bound)]\n",
        "\n",
        "df.to_excel(\"flipdata_33.xlsx\", index=False)\n"
      ],
      "metadata": {
        "id": "a0m_Ui825gSS"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}